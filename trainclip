
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
from torchvision import transforms
import logging

# Initialize logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Define Self-Attention Module
class SelfAttention(nn.Module):
    def __init__(self, embed_dim):
        super(SelfAttention, self).__init__()
        self.query = nn.Linear(embed_dim, embed_dim)
        self.key = nn.Linear(embed_dim, embed_dim)
        self.value = nn.Linear(embed_dim, embed_dim)
        self.scale = embed_dim ** 0.5

    def forward(self, x):
        Q = self.query(x)
        K = self.key(x)
        V = self.value(x)

        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale
        attention_weights = torch.softmax(attention_scores, dim=-1)

        out = torch.matmul(attention_weights, V)
        return out, attention_weights

# Define UAFDataset class
class UAFDataset(Dataset):
    def __init__(self, img_root, meta_root, genchange_root, is_train, preprocess, clip_processor, max_text_length=77):
        logger.info("Initializing UAFDataset...")
        self.img_root = img_root
        self.meta_root = meta_root
        self.genchange_root = genchange_root
        self.train_set_file = os.path.join(meta_root, 'train.txt')
        self.test_set_file = os.path.join(meta_root, 'val.txt')
        self.is_train = is_train
        self.img_process = preprocess
        self.max_text_length = max_text_length
        self.clip_processor = clip_processor

        self.samples = []
        self.text_samples = []
        self.sam_labels = []
        self.read_file = self.train_set_file if is_train else self.test_set_file

        logger.info("Reading dataset file...")
        if not os.path.exists(self.read_file):
            logger.error(f"Dataset file {self.read_file} does not exist.")
            raise FileNotFoundError(f"Dataset file {self.read_file} does not exist.")

        with open(self.read_file, 'r') as f:
            for line in f:
                parts = line.strip().split(',')
                if len(parts) < 2:
                    logger.warning(f"Skipping invalid line: {line.strip()}")
                    continue
                img_name = parts[0].strip()
                source_code = os.path.join(self.genchange_root, img_name.replace('.jpg', '.c'))

                if '-0-' in img_name:
                    label = "a photo of uaf"
                    img_path = os.path.join(self.img_root, 'uaf', img_name)
                else:
                    label = "a photo of not uaf"
                    img_path = os.path.join(self.img_root, 'not_uaf', img_name)

                if os.path.exists(source_code) and os.path.exists(img_path):
                    self.samples.append(img_path)
                    self.text_samples.append(source_code)
                    self.sam_labels.append(label)
                else:
                    if not os.path.exists(source_code):
                        logger.warning(f"Source code file {source_code} not found for {img_name}")
                    if not os.path.exists(img_path):
                        logger.warning(f"Image file {img_path} not found.")

        if not self.samples:
            logger.error("No valid samples found. Please check your dataset files.")
            raise ValueError("No valid samples found. Please check your dataset files.")

        logger.info("Tokenizing labels...")
        self.tokens = self.clip_processor.tokenizer(self.sam_labels, padding=True, return_tensors="pt")["input_ids"]
        self.labels = [0 if label == "a photo of uaf" else 1 for label in self.sam_labels]

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path = self.samples[idx]
        label = int(self.labels[idx])
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            logger.error(f"Error loading image {img_path}: {e}")
            raise e
        image = self.img_process(image)

        # Load and tokenize text
        text_path = self.text_samples[idx]
        try:
            with open(text_path, 'r') as f:
                text_data = f.read()
        except Exception as e:
            logger.error(f"Error loading text file {text_path}: {e}")
            raise e

        # Tokenize and pad text
        tokenized = self.clip_processor(text=text_data, max_length=self.max_text_length, truncation=True, return_tensors="pt")
        input_ids = tokenized['input_ids'].squeeze(0)  # Shape: [seq_length]

        return image, input_ids, label

class UAFModelWithLabels(nn.Module):
    def __init__(self, clip_model):
        super(UAFModelWithLabels, self).__init__()
        self.clip_model = clip_model
        self.self_attention = SelfAttention(embed_dim=clip_model.config.projection_dim)
        self.fc = nn.Linear(clip_model.config.projection_dim * 2 + 1, 2)  # Adjust for labels
        self.fc_aggregated = nn.Linear(clip_model.config.projection_dim, clip_model.config.projection_dim)

    def forward(self, image, input_ids, labels):
        with torch.no_grad():
            image_features = self.clip_model.get_image_features(pixel_values=image)
        text_features = self.clip_model.get_text_features(input_ids=input_ids)
        attended_features, _ = self.self_attention(text_features)
        aggregated_features = attended_features.mean(dim=1) if attended_features.dim() > 2 else attended_features
        aggregated_features = self.fc_aggregated(aggregated_features)
        label_embedding = labels.float().unsqueeze(1)
        combined_features = torch.cat((image_features, aggregated_features, label_embedding), dim=1)
        return self.fc(combined_features)





# Modify training function to pass labels to the model
def train_model(model, dataloader, optimizer, criterion, device, max_steps_per_epoch=10, num_epochs=5,
                save_dir='./models'):
    # Ensure the save directory exists
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)  # Create the directory if it doesn't exist
        logger.info(f"Directory {save_dir} created.")

    logger.info("Starting training...")
    model.train()
    for epoch in range(num_epochs):
        total_loss = 0
        logger.info(f"Epoch {epoch + 1}/{num_epochs} starting...")
        for batch_idx, (images, input_ids, labels) in enumerate(dataloader):
            if batch_idx >= max_steps_per_epoch:  # Stop after max_steps_per_epoch steps
                break

            images = images.to(device)
            input_ids = input_ids.to(device)
            labels = labels.to(device)

            # Forward pass
            optimizer.zero_grad()
            outputs = model(images, input_ids, labels)  # Pass labels as an argument
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

            # Log progress every batch
            avg_loss = total_loss / (batch_idx + 1)
            logger.info(
                f"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{max_steps_per_epoch}], Loss: {avg_loss:.4f}")

        avg_epoch_loss = total_loss / max_steps_per_epoch
        logger.info(f"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {avg_epoch_loss:.4f}")

        # Save model
        save_path = os.path.join(save_dir, f'uaf_model_epoch_{epoch + 1}.pth')
        torch.save(model.state_dict(), save_path)
        logger.info(f"Model saved at {save_path}")


# Modify checkpoint
def modify_checkpoint(checkpoint_path, model):
    checkpoint = torch.load(checkpoint_path)

    # Access the original weight
    fc_weight = checkpoint['fc.weight']
    fc_bias = checkpoint['fc.bias']  # Original bias

    # Create a new weight matrix with the additional label embedding
    new_fc_weight = torch.cat([fc_weight, torch.randn(2, 1, device=fc_weight.device)], dim=1)

    # Update the checkpoint
    checkpoint['fc.weight'] = new_fc_weight
    checkpoint['fc.bias'] = fc_bias  # Bias remains unchanged

    # Save the modified checkpoint
    torch.save(checkpoint, checkpoint_path)
    print("Checkpoint modified and saved.")


# Example usage
if __name__ == "__main__":
    # Define paths and parameters
    img_root = '/zhangliqiang/clip/copyfolder/vlm0/pdg_data/images'
    meta_root = '/zhangliqiang/clip/copyfolder/vlm0/pdg_data/meta'
    genchange_root = '/zhangliqiang/clip/copyfolder/vlm0/genchangename'

    # Initialize device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"Using device: {device}")

    # Load CLIP model and processor
    try:
        clip_model = CLIPModel.from_pretrained('/zhangliqiang/clip/copyfolder/vlm0/clip-model').to(device)
        clip_processor = CLIPProcessor.from_pretrained('/zhangliqiang/clip/copyfolder/vlm0/clip-model')
        logger.info("CLIP model and processor loaded successfully.")
    except Exception as e:
        logger.error(f"Error loading CLIP model: {e}")
        raise e

    # Initialize UAF model
    try:
        model = UAFModelWithLabels(clip_model=clip_model).to(device)
        logger.info("UAFModel initialized successfully.")

        # Load the saved checkpoint to continue training
        checkpoint_path = '/zhangliqiang/clip/copyfolder/vlm0/models/uaf_model_epoch_5.pth'
        #checkpoint_path = '/path/to/your/modified_checkpoint.pth'
        if os.path.exists(checkpoint_path):
            model.load_state_dict(torch.load(checkpoint_path))
            logger.info(f"Model weights loaded from {checkpoint_path}")
        else:
            logger.error(f"Checkpoint {checkpoint_path} not found.")
            raise FileNotFoundError(f"Checkpoint {checkpoint_path} not found.")


        # Modify the checkpoint after loading it
        modify_checkpoint(checkpoint_path, model)

    except Exception as e:
        logger.error(f"Error initializing UAFModel: {e}")
        raise e

    # Create dataset and dataloader
    try:
        preprocess = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
        ])

        train_dataset = UAFDataset(
            img_root=img_root,
            meta_root=meta_root,
            genchange_root=genchange_root,
            is_train=True,
            preprocess=preprocess,
            clip_processor=clip_processor,
            max_text_length=77
        )
        train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)
        logger.info(f"Dataset and DataLoader created successfully with {len(train_dataset)} samples.")
    except Exception as e:
        logger.error(f"Error creating dataset or dataloader: {e}")
        raise e

    # Define criterion and optimizer
    try:
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=1e-4)
        logger.info("Criterion and optimizer defined successfully.")
    except Exception as e:
        logger.error(f"Error defining criterion or optimizer: {e}")
        raise e

    # Train the model and log progress
    try:
        train_model(
            model=model,
            dataloader=train_dataloader,
            optimizer=optimizer,
            criterion=criterion,
            device=device,
            max_steps_per_epoch=10,  # Adjust as needed
            num_epochs=5,  # Adjust as needed
            save_dir='./models'  # Ensure this directory exists or create it
        )
    except Exception as e:
        logger.error(f"Error during training: {e}")
        raise e
